{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16235,"status":"ok","timestamp":1717547442916,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"4QpkGl9S7cjX","outputId":"8abc299b-260b-4510-fb7e-34927aea966f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"03AKjQjI8xLl","executionInfo":{"status":"ok","timestamp":1717547446607,"user_tz":-540,"elapsed":3693,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import json\n","\n","import math\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers as k\n","from keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1717547446608,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"3_4rgzx7tMH6","outputId":"0fe6268b-f969-452f-cc54-8eb2fbceecf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["InceptionV3_generator_03_2_only_sq_remove_class1_batch(256)_epoch(30)_tpu\n"]}],"source":["image_size = (299, 299, 3)\n","batch_num = 256\n","epoch_num = 30\n","\n","# create_model_name\n","model = 'InceptionV3_generator'\n","numbering = '03_2'\n","preprocessing_method ='only_sq'\n","class_type = 'remove_class1'\n","runtime_type = 'tpu'\n","\n","# 고정 내역\n","max_pic_cnt = 1000\n","top_layer = 'customized_top_layer'\n","\n","if runtime_type == 'tpu':\n","    model_name = f'{model}_{numbering}_{preprocessing_method}_{class_type}_batch({batch_num})_epoch({epoch_num})_tpu'\n","else :\n","    model_name = f'{model}_{numbering}_{preprocessing_method}_{class_type}_batch({batch_num})_epoch({epoch_num})'\n","print(model_name)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Bf_Kzd6VkRY6","executionInfo":{"status":"ok","timestamp":1717547447060,"user_tz":-540,"elapsed":457,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":["# create model folder\n","base_path = f'/content/drive/MyDrive/project3/image_model/{model}'\n","if not os.path.exists(base_path):\n","    os.makedirs(base_path)\n","\n","model_path = f'/content/drive/MyDrive/project3/image_model/{model}/{model_name}'\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","# result folder\n","result_path = f'/content/drive/MyDrive/project3/image_model/{model}/{model_name}/result'\n","if not os.path.exists(result_path):\n","    os.makedirs(result_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1429,"status":"ok","timestamp":1717547448487,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"QRbhunHTQt1v","outputId":"5e389ffc-bdf9-4d4e-fccd-a09d67141888"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           file_path type middle_class  \\\n","0  /content/drive/MyDrive/project3/data/traindata...  raw         구이   \n","1  /content/drive/MyDrive/project3/data/traindata...  raw         구이   \n","2  /content/drive/MyDrive/project3/data/traindata...  raw         구이   \n","3  /content/drive/MyDrive/project3/data/traindata...  raw         구이   \n","4  /content/drive/MyDrive/project3/data/traindata...  raw         구이   \n","\n","  small_class      food_class  group_number crop_area  \n","0   갈비구이  구이/갈비구이             1       NaN  \n","1   갈비구이  구이/갈비구이             2       NaN  \n","2   갈비구이  구이/갈비구이             3       NaN  \n","3   갈비구이  구이/갈비구이             4       NaN  \n","4   갈비구이  구이/갈비구이             5       NaN  "],"text/html":["\n","  <div id=\"df-4fe5fe10-b589-4449-bd81-179a3f58eb79\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_path</th>\n","      <th>type</th>\n","      <th>middle_class</th>\n","      <th>small_class</th>\n","      <th>food_class</th>\n","      <th>group_number</th>\n","      <th>crop_area</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/project3/data/traindata...</td>\n","      <td>raw</td>\n","      <td>구이</td>\n","      <td>갈비구이</td>\n","      <td>구이/갈비구이</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/project3/data/traindata...</td>\n","      <td>raw</td>\n","      <td>구이</td>\n","      <td>갈비구이</td>\n","      <td>구이/갈비구이</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/project3/data/traindata...</td>\n","      <td>raw</td>\n","      <td>구이</td>\n","      <td>갈비구이</td>\n","      <td>구이/갈비구이</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/project3/data/traindata...</td>\n","      <td>raw</td>\n","      <td>구이</td>\n","      <td>갈비구이</td>\n","      <td>구이/갈비구이</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/project3/data/traindata...</td>\n","      <td>raw</td>\n","      <td>구이</td>\n","      <td>갈비구이</td>\n","      <td>구이/갈비구이</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fe5fe10-b589-4449-bd81-179a3f58eb79')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4fe5fe10-b589-4449-bd81-179a3f58eb79 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4fe5fe10-b589-4449-bd81-179a3f58eb79');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-675571a5-b179-49d4-a2fe-4dd95a937caf\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-675571a5-b179-49d4-a2fe-4dd95a937caf')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-675571a5-b179-49d4-a2fe-4dd95a937caf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":5}],"source":["df = pd.read_pickle('/content/drive/MyDrive/project3/data/traindata/read_image.pkl')\n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1717547448488,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"IZbAsQG5Qt3_","outputId":"e9b64fc5-2838-4c34-ca93-ff98e70026f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150283, 7)"]},"metadata":{},"execution_count":6}],"source":["df.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Kt0uK1u8RWJf","executionInfo":{"status":"ok","timestamp":1717547448934,"user_tz":-540,"elapsed":451,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":["remove_class1_list = '/content/drive/MyDrive/project3/image_model/check_matrix/remove_class1.txt'\n","\n","with open(remove_class1_list, 'r', encoding='utf-8') as file:\n","    remove_class1 = [line.strip() for line in file]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717547448934,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"uVVOxZ0gOKnf","outputId":"05475e3b-deb8-4e70-917e-113dab5c0f01"},"outputs":[{"output_type":"stream","name":"stdout","text":["114\n"]}],"source":["print(len(remove_class1))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1717547449230,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"vNnLet1kOKwK","outputId":"2d24264f-69ee-4697-f467-c534b710be54"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(113914, 7)"]},"metadata":{},"execution_count":9}],"source":["# 남아 있는 클래스만 대상으로\n","df = df[df['food_class'].isin(remove_class1)]\n","df.shape"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cVXqRN3pOKyK","executionInfo":{"status":"ok","timestamp":1717547449230,"user_tz":-540,"elapsed":4,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"baiVCxINRnQA","executionInfo":{"status":"ok","timestamp":1717547449230,"user_tz":-540,"elapsed":4,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"hKjMSLGMQt6V","executionInfo":{"status":"ok","timestamp":1717547449230,"user_tz":-540,"elapsed":4,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":["train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['small_class'])\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['small_class'])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717547449231,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"8N35IuV5Qt8q","outputId":"00206f41-ce09-4a0b-cd40-fadf726bbd6b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((91131, 7), (11391, 7), (11392, 7))"]},"metadata":{},"execution_count":11}],"source":["train_df.shape, val_df.shape, test_df.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"gx9SPM_7NSlf","executionInfo":{"status":"ok","timestamp":1717547449231,"user_tz":-540,"elapsed":3,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"tPZIgOVcnwZ0","executionInfo":{"status":"ok","timestamp":1717547450667,"user_tz":-540,"elapsed":1439,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","import cv2\n","\n","def process_image(image_array, new_ratio=1.5, new_image_size=299):\n","    height, width, _ = image_array.shape\n","\n","    if width == height:\n","        new_image = cv2.resize(image_array, (new_image_size, new_image_size), interpolation=cv2.INTER_LINEAR)\n","        return new_image\n","\n","    ratio = width / height if width > height else height / width\n","\n","    if ratio > new_ratio:\n","        return None\n","\n","    if width > height:\n","        new_width = int(height)\n","        left = (width - new_width) / 2\n","        right = (width + new_width) / 2\n","        top = 0\n","        bottom = height\n","    else:\n","        new_height = int(width)\n","        left = 0\n","        right = width\n","        top = (height - new_height) / 2\n","        bottom = (height + new_height) / 2\n","\n","    cropped_image = image_array[int(top):int(bottom), int(left):int(right)]\n","\n","    new_size = max(cropped_image.shape[:2])\n","\n","    black_background = np.full((new_size, new_size, 3), 0, dtype=np.uint8)\n","    black_y_offset = (new_size - cropped_image.shape[0]) // 2\n","    black_x_offset = (new_size - cropped_image.shape[1]) // 2\n","\n","    black_background[black_y_offset:black_y_offset+cropped_image.shape[0],\n","                     black_x_offset:black_x_offset+cropped_image.shape[1]] = cropped_image\n","\n","    new_image = cv2.resize(black_background, (new_image_size, new_image_size), interpolation=cv2.INTER_LINEAR)\n","    new_image = new_image.astype(np.uint8)\n","\n","    return new_image\n","\n","class CustomImageDataGenerator(ImageDataGenerator):\n","    def flow_from_directory(self, directory, target_size=(299, 299), *args, **kwargs):\n","        generator = super().flow_from_directory(directory, target_size=target_size, *args, **kwargs)\n","        while True:\n","            batch_x, batch_y = next(generator)\n","            new_batch_x = []\n","            new_batch_y = []\n","            for i in range(len(batch_x)):\n","                img = load_img(generator.filepaths[generator.index_array[i]])\n","                img_array = img_to_array(img)\n","                processed_img = process_image(img_array, new_image_size=target_size[0])\n","                if processed_img is not None:\n","                    new_batch_x.append(processed_img)\n","                    new_batch_y.append(batch_y[i])\n","            if new_batch_x:\n","                yield np.array(new_batch_x), np.array(new_batch_y)\n","\n","# 데이터 생성기 설정\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"AhDNA7JUKukA","executionInfo":{"status":"ok","timestamp":1717547450668,"user_tz":-540,"elapsed":6,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"}}},"outputs":[],"source":["## non_proprocessing\n","# train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# only flip\n","# train_datagen = ImageDataGenerator(\n","#     rescale=1./255,\n","#     horizontal_flip=True  # 수평 플립만 적용\n","# )\n","\n","\n","# ## only_gen\n","# train_datagen = ImageDataGenerator(\n","#     rescale=1./255,\n","#     rotation_range=20,\n","#     width_shift_range=0.2,\n","#     height_shift_range=0.2,\n","#     shear_range=0.2,\n","#     zoom_range=0.2,\n","#     horizontal_flip=True,\n","#     fill_mode='nearest'\n","# )\n","\n","# only_sq\n","train_datagen = CustomImageDataGenerator(\n","    rescale=1./255,\n",")\n","\n","## sq + gen\n","# train_datagen = CustomImageDataGenerator(\n","#     rescale=1./255,\n","#     rotation_range=20,\n","#     width_shift_range=0.2,\n","#     height_shift_range=0.2,\n","#     shear_range=0.2,\n","#     zoom_range=0.2,\n","#     horizontal_flip=True,\n","#     fill_mode='nearest'\n","# )\n","\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312621,"status":"ok","timestamp":1717547763284,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"si74Og0kKumP","outputId":"78b4ef5e-c35a-4cb7-e6c6-737a83683892"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 91131 validated image filenames belonging to 114 classes.\n","Found 11391 validated image filenames belonging to 114 classes.\n","Found 11392 validated image filenames belonging to 114 classes.\n"]}],"source":["new_image_size = (299, 299)\n","\n","train_generator = train_datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='file_path',\n","    y_col='small_class',\n","    target_size=new_image_size,\n","    batch_size=batch_num,\n","    class_mode='categorical',\n","    shuffle=True\n",")\n","\n","val_generator = val_datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='file_path',\n","    y_col='small_class',\n","    target_size=new_image_size,\n","    batch_size=batch_num,\n","    class_mode='categorical',\n","    shuffle=True\n",")\n","\n","test_generator = test_datagen.flow_from_dataframe(\n","    test_df,\n","    x_col='file_path',\n","    y_col='small_class',\n","    target_size=new_image_size,\n","    batch_size=batch_num,\n","    class_mode='categorical',\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717547763284,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"u8DJ4a2NTLx5","outputId":"121a0835-cf52-4651-a372-6da7b7c0e7a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 114\n"]}],"source":["num_classes = len(train_generator.class_indices)\n","print(\"Number of classes:\", num_classes)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10264,"status":"ok","timestamp":1717547773547,"user":{"displayName":"JinSeok Song","userId":"14796603013551188771"},"user_tz":-540},"id":"9dKhkmpVKuoh","outputId":"275614b4-c55c-406e-b483-9da446ab5b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n","                                                                 \n"," global_average_pooling2d (  (None, 2048)              0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1049088   \n","                                                                 \n"," batch_normalization_94 (Ba  (None, 512)               2048      \n"," tchNormalization)                                               \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," batch_normalization_95 (Ba  (None, 256)               1024      \n"," tchNormalization)                                               \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 114)               29298     \n","                                                                 \n","=================================================================\n","Total params: 23015570 (87.80 MB)\n","Trainable params: 1211250 (4.62 MB)\n","Non-trainable params: 21804320 (83.18 MB)\n","_________________________________________________________________\n","None\n"]}],"source":["# Load the InceptionV3\n","# model pre-trained -> by imagenet dataset\n","# without the top layer -> 마지막 결과를 내는 레이어 층에 관한\n","inception = InceptionV3(weights='imagenet', input_shape=[299, 299, 3], include_top=False)\n","inception.trainable = False  # Freeze the layers of InceptionV3\n","\n","# Define the Customized top layer\n","model = tf.keras.models.Sequential([\n","    inception,\n","    k.GlobalAveragePooling2D(),\n","    k.Dropout(0.2),\n","    k.Dense(512, activation='relu'),\n","    k.BatchNormalization(),\n","    k.Dropout(0.1),\n","    k.Dense(256, activation='relu'),\n","    k.BatchNormalization(),\n","    k.Dropout(0.1),\n","    k.Dense(num_classes, activation='softmax')\n","])\n","\n","print(model.summary())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rn6pn-T5Kuq4","outputId":"13416711-700e-422b-e086-d772f260184e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","356/356 [==============================] - ETA: 0s - loss: 1.8845 - categorical_accuracy: 0.5023 - precision: 0.7850 - recall: 0.3152 "]}],"source":["early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint(filepath=os.path.join(model_path, f'{model_name}_best.h5'),\n","                                   monitor='val_loss', save_best_only=True)\n","\n","\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",")\n","\n","history = model.fit_generator(train_generator,\n","                              epochs=epoch_num,\n","                              steps_per_epoch= len(train_generator),\n","                              validation_data = val_generator,\n","                              validation_steps= len(val_generator),\n","                              use_multiprocessing=True,\n","                              callbacks=[model_checkpoint, early_stopping]\n","                              )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqasAKQ3UbmZ"},"outputs":[],"source":["# model save\n","model.save(os.path.join(model_path, f'{model_name}.h5'))\n","\n","\n","# training history save\n","with open(os.path.join(result_path, f'{model_name}_history.json'), 'w') as f:\n","    json.dump(history.history, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP703m-2Uxm_"},"outputs":[],"source":["plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['categorical_accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Accuracy By Epochs')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Loss By Epochs')\n","\n","plt.suptitle(f'{model_name}')\n","\n","# save training_plot\n","plt.savefig(os.path.join(result_path, f'{model_name}_training_plot.png'))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEXcqW37tk1g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yLXYnR36U1ke"},"outputs":[],"source":["y_pred = model.predict(test_generator)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = test_generator.classes\n","\n","conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n","\n","# Print classification report for detailed metrics\n","class_report = classification_report(y_true_classes, y_pred_classes, target_names=test_generator.class_indices.keys())\n","print(class_report)\n","\n","with open(os.path.join(result_path, f'{model_name}_classification_report.txt'), 'w') as f:\n","    f.write(class_report)\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title(f'{model_name} Confusion Matrix')\n","\n","plt.savefig(os.path.join(result_path, f'{model_name}_confusion_matrix.png'))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"niaduEZcU6Il"},"outputs":[],"source":["\n","# Calculate accuracy using sklearn\n","accuracy = accuracy_score(y_true_classes, y_pred_classes)\n","print('Accuracy:', accuracy)\n","\n","# Calculate precision and recall using sklearn\n","precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n","recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n","print('Precision:', precision)\n","print('Recall:', recall)\n","\n","# Append accuracy to a text file\n","with open(os.path.join(base_path, 'accuracy.txt'), 'a') as f:\n","    f.write(f'{model_name}_Accuracy: {accuracy:.2f}%\\n')\n","    f.write(f'{model_name}_Precision: {precision:.2f}%\\n')\n","    f.write(f'{model_name}_Recall: {recall:.2f}%\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ciH3Tudtl39a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WP0T-80JYm_i"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2HuZ-As6YnBv"},"outputs":[],"source":["val_prediction = model.predict_generator(val_generator, steps = len(val_generator))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AgRV2XDYnEI"},"outputs":[],"source":["food_classes = val_generator.class_indices\n","print(food_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSaVSMjnYnGi"},"outputs":[],"source":["# y가 예측한 레이블\n","val_y_pred = np.argmax(val_prediction, axis = 1)\n","# 실제 y 값\n","val_y_true = val_generator.classes\n","\n","print(\"val_y_pred ===  \", val_y_pred[:50])\n","print(\"val_y_true ===  \", val_y_true[:50])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDLBurhAXYSz"},"outputs":[],"source":["# confusion_matrix\n","food_confusion_matrix = confusion_matrix(val_y_true, val_y_pred)\n","print(food_confusion_matrix)\n","print(\"shape==\", food_confusion_matrix.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeO3S2gpXYVJ"},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","\n","# 단순히 갯수로 비교하면 이미지가 많은 클래스가 상대적으로 나쁘게 보일 수 있다.\n","# 현재 validation set의 class별 이미지 갯수는 전처리 과정에서 일부 누락된 게 있어 모두 100개가 아님\n","# --> 비율로 confusion_matrix를 normalize한다!\n","\n","row_sums = food_confusion_matrix.sum(axis=1, keepdims=True)\n","norm_conf_mx = food_confusion_matrix / row_sums\n","\n","df_cm = pd.DataFrame(norm_conf_mx, index = range(num_classes),columns=range(num_classes))\n","\n","plt.figure(figsize = (20,14))\n","plt.title(\"confusion_matrix (x : Predicted, y : Actual) \")\n","\n","sns.heatmap(df_cm, annot=False, cmap=\"Blues\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DTFb3SCXYXu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNG1n5BtXYZq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfI42xB5l3_q"},"outputs":[],"source":["# 각 index별 음식 이름\n","food_classes = val_generator.class_indices\n","print(food_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s69HJbDpl5FA"},"outputs":[],"source":["# food_dict -> key : 음식 이름, value : index인 dictionary\n","food_dict = val_generator.class_indices\n","# foods_prob : (음식 이름, 음식의 index, 예측값=실제값일 확률)인 tuple을 각 원소로 갖는 list\n","foods_prob = [(food_name,idx, prob) for food_name, idx, prob in zip(food_dict.keys(), food_dict.values() ,np.diag(norm_conf_mx))]\n","foods_prob =  sorted(foods_prob,key= lambda x : x[2])\n","print(foods_prob)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xijX7zqCl905"},"outputs":[],"source":["# 잘 분류될 확률이 60% 이하인 음식들\n","bad_classfifed_foods = [food_prob for food_prob in foods_prob if food_prob[2] <= 0.6 ]\n","bad_classfifed_foods"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyM6SfEcDKDhM0FoZ/C6TggW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}